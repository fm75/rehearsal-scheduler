{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b3fbd3-a25f-472e-a024-1b60d521a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rehearsal_scheduler.constraints import DayOfWeekConstraint, TimeOnDayConstraint\n",
    "\n",
    "# constraint_text = \"sun  1700-1900\"\n",
    "# constraint_text = \"sun before 1700\"\n",
    "# constraint_text = \"sun after 1700\"\n",
    "# constraint_text = \"f before 9am\"\n",
    "constraint_text = \"f before 9\"\n",
    "# constraint_text = \"sat before 10am\"\n",
    "constraint_text = \"m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967a3401-683d-4a5c-9908-9db5c3bc053b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_spec <class 'str'>: 'monday'\n",
      "temporal_constraint  <class 'str'>: 'monday' <class 'NoneType'>: None\n",
      "constraint <class 'rehearsal_scheduler.constraints.DayOfWeekConstraint'>: DayOfWeekConstraint(day_of_week='monday')\n",
      "\n",
      "res = (DayOfWeekConstraint(day_of_week='monday'),)\n"
     ]
    }
   ],
   "source": [
    "from rehearsal_scheduler.grammar import constraint_parser\n",
    "constraint_text = \"m\"\n",
    "parser = constraint_parser(debug=True)\n",
    "result = parser.parse(constraint_text)\n",
    "print(f\"\\nres = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d19168-3388-46f9-81c8-f8aceab70991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "military_time <class 'list'>: [10, 0]\n",
      "tod <class 'list'>: [(10, 0)]\n",
      "\n",
      "res = 10:00:00\n"
     ]
    },
    {
     "ename": "UnexpectedToken",
     "evalue": "Unexpected token Token('AM_PM', 'am') at line 1, column 3.\nExpected one of: \n\t* MINUTE\nPrevious tokens: [Token('MORNING_MIL', '10')]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedCharacters\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/lexer.py:689\u001b[39m, in \u001b[36mContextualLexer.lex\u001b[39m\u001b[34m(self, lexer_state, parser_state)\u001b[39m\n\u001b[32m    688\u001b[39m         lexer = \u001b[38;5;28mself\u001b[39m.lexers[parser_state.position]\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mlexer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/lexer.py:622\u001b[39m, in \u001b[36mBasicLexer.next_token\u001b[39m\u001b[34m(self, lex_state, parser_state)\u001b[39m\n\u001b[32m    621\u001b[39m         allowed = {\u001b[33m\"\u001b[39m\u001b[33m<END-OF-FILE>\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state.text.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,\n\u001b[32m    623\u001b[39m                                allowed=allowed, token_history=lex_state.last_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state.last_token],\n\u001b[32m    624\u001b[39m                                state=parser_state, terminals_by_name=\u001b[38;5;28mself\u001b[39m.terminals_by_name)\n\u001b[32m    626\u001b[39m value, type_ = res\n",
      "\u001b[31mUnexpectedCharacters\u001b[39m: No terminal matches 'a' in the current parser context, at line 1 col 3\n\n10am\n  ^\nExpected one of: \n\t* MINUTE\n\nPrevious tokens: Token('MORNING_MIL', '10')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnexpectedToken\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 122\u001b[39m\n\u001b[32m    120\u001b[39m result = parser.parse(\u001b[33m\"\u001b[39m\u001b[33m1000\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mres = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m result = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m10am\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mres = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/lark.py:677\u001b[39m, in \u001b[36mLark.parse\u001b[39m\u001b[34m(self, text, start, on_error)\u001b[39m\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options.parser != \u001b[33m'\u001b[39m\u001b[33mlalr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe on_error option is only implemented for the LALR(1) parser.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/parser_frontends.py:131\u001b[39m, in \u001b[36mParsingFrontend.parse\u001b[39m\u001b[34m(self, text, start, on_error)\u001b[39m\n\u001b[32m    129\u001b[39m kw = {} \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33mon_error\u001b[39m\u001b[33m'\u001b[39m: on_error}\n\u001b[32m    130\u001b[39m stream = \u001b[38;5;28mself\u001b[39m._make_lexer_thread(text)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/parsers/lalr_parser.py:42\u001b[39m, in \u001b[36mLALR_Parser.parse\u001b[39m\u001b[34m(self, lexer, start, on_error)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lexer, start, on_error=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/parsers/lalr_parser.py:88\u001b[39m, in \u001b[36m_Parser.parse\u001b[39m\u001b[34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_interactive:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state.lexer)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/parsers/lalr_parser.py:111\u001b[39m, in \u001b[36m_Parser.parse_from_state\u001b[39m\u001b[34m(self, state, last_token)\u001b[39m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/parsers/lalr_parser.py:100\u001b[39m, in \u001b[36m_Parser.parse_from_state\u001b[39m\u001b[34m(self, state, last_token)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     99\u001b[39m     token = last_token\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/rehearsal-scheduler/venv/lib/python3.13/site-packages/lark/lexer.py:698\u001b[39m, in \u001b[36mContextualLexer.lex\u001b[39m\u001b[34m(self, lexer_state, parser_state)\u001b[39m\n\u001b[32m    696\u001b[39m     last_token = lexer_state.last_token  \u001b[38;5;66;03m# Save last_token. Calling root_lexer.next_token will change this to the wrong token\u001b[39;00m\n\u001b[32m    697\u001b[39m     token = \u001b[38;5;28mself\u001b[39m.root_lexer.next_token(lexer_state, parser_state)\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, e.allowed, state=parser_state, token_history=[last_token], terminals_by_name=\u001b[38;5;28mself\u001b[39m.root_lexer.terminals_by_name)\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedCharacters:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mUnexpectedToken\u001b[39m: Unexpected token Token('AM_PM', 'am') at line 1, column 3.\nExpected one of: \n\t* MINUTE\nPrevious tokens: [Token('MORNING_MIL', '10')]\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from datetime import time\n",
    "\n",
    "from lark import Lark, Transformer, v_args\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def type_and_value(obj):  # pragma: no cover\n",
    "    \"\"\"Helper for debugging: returns the type and value of an object.\"\"\"\n",
    "    if DEBUG:  # pragma: no cover\n",
    "        return f\"{type(obj)}: {repr(obj)}\"\n",
    "    return \"\"  # pragma: no cover\n",
    "\n",
    "\n",
    "GRAMMAR = r\"\"\"\n",
    "    ?start: tod\n",
    "    \n",
    "    tod: std_time | military_time\n",
    "    \n",
    "    std_time: HOUR_STD (\":\" MINUTE)? AM_PM?\n",
    "    military_time : (MORNING_MIL | AFTERNOON_MIL) MINUTE\n",
    "    \n",
    "    // TERMINALS\n",
    "    \n",
    "    HOUR_STD: \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\" | \"10\" | \"11\" | \"12\"\n",
    "\n",
    "    MORNING_MIL:   \"00\" | \"01\" | \"02\" | \"03\" | \"04\" | \"05\" | \"06\" | \"07\" | \"08\" | \"09\" | \"10\" | \"11\" \n",
    "    AFTERNOON_MIL: \"12\" | \"13\" | \"14\" | \"15\" | \"16\" | \"17\" | \"18\" | \"19\" | \"20\" | \"21\" | \"22\" | \"23\"\n",
    "\n",
    "    MINUTE : \"0\" \"0\" | \"0\" \"1\" | \"0\" \"2\" | \"0\" \"3\" | \"0\" \"4\" | \"0\" \"5\" | \"0\" \"6\" | \"0\" \"7\" | \"0\" \"8\" | \"0\" \"9\" \n",
    "           | \"1\" \"0\" | \"1\" \"1\" | \"1\" \"2\" | \"1\" \"3\" | \"1\" \"4\" | \"1\" \"5\" | \"1\" \"6\" | \"1\" \"7\" | \"1\" \"8\" | \"1\" \"9\" \n",
    "           | \"2\" \"0\" | \"2\" \"1\" | \"2\" \"2\" | \"2\" \"3\" | \"2\" \"4\" | \"2\" \"5\" | \"2\" \"6\" | \"2\" \"7\" | \"2\" \"8\" | \"2\" \"9\" \n",
    "           | \"3\" \"0\" | \"3\" \"1\" | \"3\" \"2\" | \"3\" \"3\" | \"3\" \"4\" | \"3\" \"5\" | \"3\" \"6\" | \"3\" \"7\" | \"3\" \"8\" | \"3\" \"9\" \n",
    "           | \"4\" \"0\" | \"4\" \"1\" | \"4\" \"2\" | \"4\" \"3\" | \"4\" \"4\" | \"4\" \"5\" | \"4\" \"6\" | \"4\" \"7\" | \"4\" \"8\" | \"4\" \"9\" \n",
    "           | \"5\" \"0\" | \"5\" \"1\" | \"5\" \"2\" | \"5\" \"3\" | \"5\" \"4\" | \"5\" \"5\" | \"5\" \"6\" | \"5\" \"7\" | \"5\" \"8\" | \"5\" \"9\"\n",
    "\n",
    "    AM_PM: \"am\"i | \"pm\"i\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@v_args(inline=True)\n",
    "class ConstraintTransformer(Transformer):\n",
    "    \"\"\"Transforms the parsed Lark tree into constraint objects.\"\"\"\n",
    "\n",
    "    def INT(self, i):\n",
    "        return int(i)\n",
    "\n",
    "    def MORNING_MIL(self, h):\n",
    "        return int(h)\n",
    "\n",
    "    def AFTERNOON_MIL(self, h):\n",
    "        return int(h)\n",
    "\n",
    "    def HOUR_STD(self, h):\n",
    "        return int(h)\n",
    "\n",
    "    def MINUTE(self, m):\n",
    "        return int(m)\n",
    "\n",
    "    def AM_PM(self, am_pm):\n",
    "        if DEBUG:  # pragma: no cover\n",
    "            print(f\"{inspect.stack()[0][3]} {type_and_value(am_pm)}\")\n",
    "        return am_pm.lower()\n",
    "\n",
    "    @v_args(inline=False)\n",
    "    def military_time(self, children):\n",
    "        if DEBUG:  # pragma: no cover\n",
    "            print(f\"{inspect.stack()[0][3]} {type_and_value(children)}\")\n",
    "        hour, minute = children\n",
    "        return (hour, minute)\n",
    "\n",
    "    @v_args(inline=False)\n",
    "    def tod(self, children):\n",
    "        if DEBUG:  # pragma: no cover\n",
    "            print(f\"{inspect.stack()[0][3]} {type_and_value(children)}\")\n",
    "        h, m = children[0]\n",
    "        return time(h, m)\n",
    "\n",
    "    @v_args(inline=False)\n",
    "    def std_time(self, children):\n",
    "        \"\"\"possible inputs\n",
    "        h        : 10,11 = am, everything else is pm, m = 0\n",
    "        h ampm   : h 0 ampm\n",
    "        h m      : same rule for hours as h\n",
    "        h m ampm :\n",
    "        \"\"\"\n",
    "        if DEBUG:  # pragma: no cover\n",
    "            print(f\"{inspect.stack()[0][3]} {type_and_value(children)}\")\n",
    "        if len(children) == 3:\n",
    "            h, m, fmt = children\n",
    "            if fmt == \"pm\":\n",
    "                h += 12\n",
    "            return (h, m)\n",
    "        if len(children) == 2:\n",
    "            h, opt = children\n",
    "            if isinstance(opt, str):\n",
    "                if opt == \"pm\":\n",
    "                    h += 12\n",
    "                return (h, 0)\n",
    "            else:\n",
    "                if h not in [10, 11]:\n",
    "                    h += 12\n",
    "                return (h, opt)\n",
    "\n",
    "        h = children[0]\n",
    "        if h not in [10, 11]:\n",
    "            h += 12\n",
    "        return (h, 0)\n",
    "\n",
    "\n",
    "def constraint_parser(grammar=GRAMMAR, debug=False):\n",
    "    constraint_transformer = ConstraintTransformer()\n",
    "    global DEBUG\n",
    "    DEBUG = debug\n",
    "    return Lark(grammar, parser=\"lalr\", transformer=constraint_transformer, debug=debug)\n",
    "\n",
    "\n",
    "parser = constraint_parser(debug=True)\n",
    "result = parser.parse(\"1000\")\n",
    "print(f\"\\nres = {result}\")\n",
    "result = parser.parse(\"10am\")\n",
    "print(f\"\\nres = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5541c60-07c1-4cd1-9ae8-44422f56af8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rehearsal_scheduler.grammar_new'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlark\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrehearsal_scheduler\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrammar_new\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constraint_parser\n\u001b[32m      4\u001b[39m constraint_text = \u001b[33m\"\u001b[39m\u001b[33mm 2401-2501\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m parser = constraint_parser(debug=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'rehearsal_scheduler.grammar_new'"
     ]
    }
   ],
   "source": [
    "import lark\n",
    "from rehearsal_scheduler.grammar_new import constraint_parser\n",
    "\n",
    "constraint_text = \"m 2401-2501\"\n",
    "parser = constraint_parser(debug=True)\n",
    "exc = None\n",
    "try:\n",
    "    result = parser.parse(constraint_text)\n",
    "    print(f\"\\nres = {result}\")\n",
    "except (\n",
    "    lark.exceptions.UnexpectedToken,\n",
    "    lark.exceptions.UnexpectedCharacters,\n",
    "    SyntaxError,\n",
    ") as e:\n",
    "    exc = e\n",
    "    print(f\"Syntax error {e}\")\n",
    "except Exception as e:\n",
    "    print(type(e))\n",
    "    print(f\"Error {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc87fb3-9110-47b3-ba8c-f67f8f51ab89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rehearsal_scheduler.grammar_new import constraint_parser\n",
    "\n",
    "parser = constraint_parser(debug=True)\n",
    "result = parser.parse(constraint_text)\n",
    "print(f\"\\nres = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b6ea8-99ca-4041-933e-67f8104d1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b812be-36bc-4d6a-acdd-1898b6bcb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc.line, exc.expected, exc.token, exc.pos_in_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfbfa7-3828-4cdc-887d-74cb10d60d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"found {exc.line} at position {exc.pos_in_stream + 1} in '{constraint_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e053e-dd99-48a7-920e-c90f53c44c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc.line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8766fc-25b8-4bc6-9c66-08543c752638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exc.UnexpectedToken())\n",
    "help(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582607b2-7b3c-4321-94f5-69a57ac10b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670ab8b-34c9-4230-9137-15a79b538aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ef26b-691c-4ab9-aaef-43a1a1a7876c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36178-8801-4424-819b-446aebe62ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a4e90-abdc-4fe3-a419-1baec010b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678d8db-186d-4bec-86b3-cf26461d7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (\"a\") == (\"a\",),\n",
    "    len(\"a\"),\n",
    "    len(\n",
    "        \"a\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84645577-b1b6-4423-9729-27946331dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_conflict(\n",
    "    rehearsal: RehearsalSlot, dancer_constraints: list[UnavailabilityConstraint]\n",
    ") -> list[TimeInterval]:\n",
    "    \"\"\"Checks for conflicts and returns a list of conflicting intervals.\"\"\"\n",
    "    all_conflicts = []\n",
    "    for constraint in dancer_constraints:\n",
    "        # print(f\"constraint is {constraint}\")\n",
    "        conflicting_intervals = constraint.get_conflicting_intervals(rehearsal)\n",
    "        all_conflicts.extend(conflicting_intervals)\n",
    "    return all_conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e01c2fc-0dc7-48f8-88c8-470842e05aa1",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64753724-c34d-4198-ab16-f06823c54c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rehearsal_scheduler.constraints import RehearsalSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1ba89-7e8b-4154-ad8c-a0380dece0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import TypeAlias\n",
    "\n",
    "TimeInterval: TypeAlias = tuple[int, int]\n",
    "\n",
    "\n",
    "class UnavailabilityConstraint(ABC):\n",
    "    \"\"\"Abstract base class for all dancer unavailability constraints.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_conflicting_intervals(self, slot: RehearsalSlot) -> list[TimeInterval]:\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class DayOfWeekConstraint(UnavailabilityConstraint):\n",
    "    \"\"\"Represents an unavailability for an entire day of the week.\"\"\"\n",
    "\n",
    "    day_of_week: str\n",
    "\n",
    "    def get_conflicting_intervals(self, slot: RehearsalSlot) -> list[TimeInterval]:\n",
    "        if self.day_of_week == slot.day_of_week:\n",
    "            return [(slot.start_time, slot.end_time)]\n",
    "        return []\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class TimeOnDayConstraint(UnavailabilityConstraint):\n",
    "    \"\"\"\n",
    "    Represents an unavailability for a specific time interval on a given day of the week.\n",
    "    e.g., \"Mondays from 900 to 1200\"\n",
    "    \"\"\"\n",
    "\n",
    "    day_of_week: str  # e.g., 'monday'\n",
    "    start_time: int  # Military time, e.g., 900\n",
    "    end_time: int  # Military time, e.g., 1200\n",
    "\n",
    "    def get_conflicting_intervals(self, slot: RehearsalSlot) -> list[TimeInterval]:\n",
    "        \"\"\"\n",
    "        Checks for conflicts if the day matches AND the time intervals overlap.\n",
    "        \"\"\"\n",
    "        if self.day_of_week != slot.day_of_week:\n",
    "            return []  # No conflict if it's not on the right day.\n",
    "\n",
    "        # Classic interval overlap check: max(starts) < min(ends)\n",
    "        overlap_start = max(self.start_time, slot.start_time)\n",
    "        overlap_end = min(self.end_time, slot.end_time)\n",
    "\n",
    "        if overlap_start < overlap_end:\n",
    "            # A conflict exists! Return the actual interval of the conflict.\n",
    "            return [(overlap_start, overlap_end)]\n",
    "\n",
    "        return []"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6548a6b-8da8-4a55-9664-7ba3b58d9233",
   "metadata": {},
   "source": [
    "The Data Transformation Pipeline\n",
    "The ConstraintTransformer works from the bottom up, transforming the smallest pieces of the grammar tree first and passing the results up to the rules that contain them. Here is the precise flow for an input like \"m, w 2-4\":\n",
    "\n",
    "Parsing: The Lark parser first creates a parse tree that looks something like this (conceptually):\n",
    "\n",
    "full_spec\n",
    "  ├── constraint\n",
    "  │   └── day_spec\n",
    "  │       └── MONDAY (\"m\")\n",
    "  ├── COMMA (\",\")\n",
    "  └── constraint\n",
    "      ├── day_spec\n",
    "      │   └── WEDNESDAY (\"w\")\n",
    "      └── time_spec\n",
    "          └── time_range\n",
    "              ├── time (2)\n",
    "              └── time (4)\n",
    "Transformation Starts (Bottom-Up): The transformer then visits each node of this tree from the bottom leaves up to the top root.\n",
    "\n",
    "The MONDAY rule gets the token \"m\" and returns the string \"monday\".\n",
    "\n",
    "The day_spec rule gets the string \"monday\" and just passes it up.\n",
    "\n",
    "The first constraint method is called. It receives day_of_week_str=\"monday\" and time_spec_tuple=None. As you correctly deduced, this method acts as a factory. Since time_spec_tuple is None, it creates and returns a single DayOfWeekConstraint(day_of_week=\"monday\") object.\n",
    "\n",
    "Simultaneously, on the other branch:\n",
    "\n",
    "The INT rules transform \"2\" and \"4\" into the integers 2 and 4.\n",
    "The time methods process these into (datetime.time(2, 0), 'military') and (datetime.time(4, 0), 'military').\n",
    "The time_range method gets these two tuples, applies the heuristic to infer PM for both, and returns a new tuple: (datetime.time(14, 0), datetime.time(16, 0)).\n",
    "The time_spec rule gets this tuple and passes it up.\n",
    "The second constraint factory method is called. It receives day_of_week_str=\"wednesday\" and time_spec_tuple=(datetime.time(14, 0), datetime.time(16, 0)). It creates and returns a single TimeOnDayConstraint(...) object.\n",
    "full_spec Gathers the Results: Now we're getting to the top of the tree. The grammar rule is full_spec: constraint (\",\" constraint)*. Because this rule can match multiple constraints, Lark gathers all the Python objects returned by each constraint rule and passes them as a single Python list to the full_spec method.\n",
    "\n",
    "So, full_spec receives: [DayOfWeekConstraint(...), TimeOnDayConstraint(...)].\n",
    "My implementation of full_spec is very simple; it just returns this list as-is.\n",
    "to_tuple Finalizes the API: The very last step is defined by ?start: full_spec -> to_tuple. This means the final result from the full_spec rule is piped into the to_tuple method.\n",
    "\n",
    "to_tuple receives the list: [DayOfWeekConstraint(...), TimeOnDayConstraint(...)].\n",
    "It performs one final action: return tuple(constraints_list), which converts the list into the tuple that your original API required.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "167206d8-ed5c-4c0e-8665-1a808bfe23bb",
   "metadata": {},
   "source": [
    "Using Coverage Reports to Drive Testing\n",
    "And your plan to use the coverage report to write the next batch of tests? That is a hallmark of excellent software engineering! It's a data-driven approach that ensures your test suite is efficient and effective, focusing effort precisely where it's needed.\n",
    "\n",
    "Let's look at the line numbers you provided from the coverage report: 18, 81-83, 86, 111-112, 115.\n",
    "\n",
    "Based on the last version of the code I provided, I can make some very educated guesses about what those lines correspond to:\n",
    "\n",
    "Lines 81-83, 86: These are almost certainly inside the time method. They are the SemanticValidationError branches that I added to make the time parsing more robust.\n",
    "\n",
    "if not (0 <= minute <= 59): raise SemanticValidationError(...)\n",
    "if not (1 <= hour <= 12): raise SemanticValidationError(...)\n",
    "if not (0 <= hour <= 23): raise SemanticValidationError(...) You are absolutely right to want to exercise these. You can trigger them with inputs that are syntactically valid according to the grammar, but logically invalid. For example:\n",
    "\"m 10:60\" (invalid minute)\n",
    "\"t 13am\" (invalid hour for am/pm)\n",
    "\"w 25\" (invalid hour for military time)\n",
    "Lines 111-112, 115: These are likely inside the time_range method.\n",
    "\n",
    "if start_time >= end_time: raise SemanticValidationError(...) This is a crucial check to ensure a time range is logical. You could test this with inputs like:\n",
    "\"f 5pm-4pm\"\n",
    "\"th 1800-1700\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c37dee-7648-43af-9cce-c7bcf69cfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from lark import Lark\n",
    "from lark.exceptions import LarkError\n",
    "\n",
    "\n",
    "# Assuming your SemanticValidationError is defined as before\n",
    "class SemanticValidationError(ValueError):\n",
    "    \"\"\"Raised when the syntax is valid but the meaning is not.\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def validate_and_parse_all_constraints(\n",
    "    parser: Lark, text: str\n",
    ") -> Tuple[bool, Optional[List], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Parses a comma-separated string of constraints, validating each one individually\n",
    "    and collecting ALL errors found.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (success, results, error_message).\n",
    "        - If ALL constraints are valid, (True, [list_of_constraints], None).\n",
    "        - If ANY constraint is invalid, (False, None, \"multi-line error report\").\n",
    "    \"\"\"\n",
    "    parsed_constraints = []\n",
    "    error_messages = []\n",
    "\n",
    "    constraint_chunks = [chunk.strip() for chunk in text.split(\",\") if chunk.strip()]\n",
    "\n",
    "    if not constraint_chunks:\n",
    "        return (True, [], None)\n",
    "\n",
    "    for chunk in constraint_chunks:\n",
    "        try:\n",
    "            parsed_result = parser.parse(chunk)\n",
    "\n",
    "            # THE FIX: Use .append() to add the single object returned by the parser.\n",
    "            # .extend() would fail with a TypeError because the parsed_result is not a list.\n",
    "            parsed_constraints.append(parsed_result)\n",
    "\n",
    "        except LarkError:\n",
    "            msg = f\"- Constraint '{chunk}' is not grammatically valid.\"\n",
    "            error_messages.append(msg)\n",
    "\n",
    "        except SemanticValidationError as e:\n",
    "            msg = f\"- Constraint '{chunk}' is not logically valid: {e}\"\n",
    "            error_messages.append(msg)\n",
    "\n",
    "        except Exception as e:\n",
    "            # This block will now only catch truly unexpected errors.\n",
    "            msg = f\"- An unexpected error occurred on constraint '{chunk}': {e}\"\n",
    "            error_messages.append(msg)\n",
    "\n",
    "    if error_messages:\n",
    "        header = \"Found one or more invalid constraints:\"\n",
    "        # Corrected usage of '\\n' for newlines\n",
    "        final_error_message = f\"{header}\\n\" + \"\\n\".join(error_messages)\n",
    "        return (False, None, final_error_message)\n",
    "    else:\n",
    "        return (True, parsed_constraints, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9836a8-e72f-48eb-a630-60ec83f42dc8",
   "metadata": {},
   "source": [
    "## Grammar Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337650bd-edc0-415e-b5f3-31cfaee06167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, TypeAlias\n",
    "\n",
    "from lark import Lark, Transformer, v_args\n",
    "\n",
    "\n",
    "# --- A custom exception for semantic errors ---\n",
    "class SemanticValidationError(ValueError):\n",
    "    \"\"\"Raised when the syntax is valid but the meaning is not.\"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b0bd8a-a434-4f85-bc80-eb52d4fc2325",
   "metadata": {},
   "source": [
    "## executable code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abe1a8-ba69-4489-b69b-d60a24cb7b04",
   "metadata": {},
   "source": [
    "## Conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a802339-ee7a-40a0-a7c8-c8333e4a0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "rehearsal_1 = RehearsalSlot(\n",
    "    date(2024, 9, 4), \"wednesday\", 1800, 1930\n",
    ")  # Should conflict\n",
    "rehearsal_2 = RehearsalSlot(\n",
    "    date(2024, 9, 5), \"thursday\", 1900, 2100\n",
    ")  # Should NOT conflict\n",
    "\n",
    "conflicts_1 = check_for_conflict(rehearsal_1, parsed_constraints)\n",
    "print(f\"Checking Rehearsal 1 (Wednesday): Found conflicts: {conflicts_1}\")\n",
    "\n",
    "conflicts_2 = check_for_conflict(rehearsal_2, parsed_constraints)\n",
    "print(f\"Checking Rehearsal 2 (Thursday): Found conflicts: {conflicts_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc210cf-badb-489b-9ee1-2722dc1840df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d8856-63da-4afb-9283-a3aad3ce850b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ec514-2b83-4231-9e86-a916bccaa1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming all the classes (RehearsalSlot, constraints) and the transformer are defined above...\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "try:\n",
    "    # 1. Instantiate the parser with the new grammar and transformer\n",
    "    constraint_parser = Lark(\n",
    "        constraint_grammar,\n",
    "        start=\"start\",\n",
    "        parser=\"lalr\",\n",
    "        transformer=ConstraintTransformer(),\n",
    "    )\n",
    "\n",
    "    # 2. Define a complex unavailability string\n",
    "    dancer_unavailability_string = \"mo until 12, w 2-4, fri after 5pm, sunday\"\n",
    "\n",
    "    # 3. Parse the string\n",
    "    parsed_constraints = constraint_parser.parse(dancer_unavailability_string)\n",
    "\n",
    "    print(f\"Input string: '{dancer_unavailability_string}'\")\n",
    "    print(\"Parsed constraint objects:\")\n",
    "    for c in parsed_constraints:\n",
    "        print(f\"  - {c}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # 4. Define rehearsals to check\n",
    "    rehearsal_ok = RehearsalSlot(\n",
    "        date(2024, 9, 2), \"monday\", 1300, 1500\n",
    "    )  # OK, it's after 1200\n",
    "    rehearsal_conflict_1 = RehearsalSlot(\n",
    "        date(2024, 9, 2), \"monday\", 1100, 1230\n",
    "    )  # CONFLICT, overlaps with \"until 1200\"\n",
    "    rehearsal_conflict_2 = RehearsalSlot(\n",
    "        date(2024, 9, 4), \"wednesday\", 1500, 1700\n",
    "    )  # CONFLICT, overlaps with 1400-1600\n",
    "    rehearsal_conflict_3 = RehearsalSlot(\n",
    "        date(2024, 9, 8), \"sunday\", 1000, 1100\n",
    "    )  # CONFLICT, unavailable all day Sunday\n",
    "\n",
    "    # 5. Check for conflicts\n",
    "    print(f\"Checking {rehearsal_ok.day_of_week} at {rehearsal_ok.start_time}:\")\n",
    "    print(f\"  -> Conflicts: {check_for_conflict(rehearsal_ok, parsed_constraints)}\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"Checking {rehearsal_conflict_1.day_of_week} at {rehearsal_conflict_1.start_time}:\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  -> Conflicts: {check_for_conflict(rehearsal_conflict_1, parsed_constraints)}\\n\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Checking {rehearsal_conflict_2.day_of_week} at {rehearsal_conflict_2.start_time}:\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  -> Conflicts: {check_for_conflict(rehearsal_conflict_2, parsed_constraints)}\\n\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Checking {rehearsal_conflict_3.day_of_week} at {rehearsal_conflict_3.start_time}:\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  -> Conflicts: {check_for_conflict(rehearsal_conflict_3, parsed_constraints)}\\n\"\n",
    "    )\n",
    "\n",
    "    # 6. Test the validation\n",
    "    print(\"Testing invalid input 'th after 25'...\")\n",
    "    invalid_string = \"th after 25\"\n",
    "    constraint_parser.parse(invalid_string)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Successfully caught expected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cccf00-37e8-4adb-8880-c72ae6a870bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8facab1b-8665-41b3-86ea-f7ad20e808db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'constraint_parser' is your Lark instance with the ConstraintTransformer\n",
    "\n",
    "# A string with a syntactic error (\"zulu\") and a semantic error (\"th after 99\")\n",
    "test_text_multiple_errors = \"Monday, zulu, th after 99, wed\"\n",
    "\n",
    "print(f\"Checking: '{test_text_multiple_errors}'\")\n",
    "ok, constraints, errors = validate_and_parse_all_constraints(\n",
    "    constraint_parser, test_text_multiple_errors\n",
    ")\n",
    "\n",
    "if ok:\n",
    "    print(\"\\nSuccess! Parsed constraints:\")\n",
    "    for c in constraints:\n",
    "        print(f\"  - {c}\")\n",
    "else:\n",
    "    print(f\"\\nFailure! Reasons:\\n{errors}\")\n",
    "\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f8b99-1c12-4222-a46f-4e32ecf8cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fully valid string for comparison\n",
    "test_text_valid = \"mo until 12, w 2-4, fri after 5pm\"\n",
    "print(f\"Checking: '{test_text_valid}'\")\n",
    "ok, constraints, errors = validate_and_parse_all_constraints(\n",
    "    constraint_parser, test_text_valid\n",
    ")\n",
    "\n",
    "if ok:\n",
    "    print(\"\\nSuccess! Parsed constraints:\")\n",
    "    for c in constraints:\n",
    "        print(f\"  - {c}\")\n",
    "else:\n",
    "    print(f\"\\nFailure! Reasons:\\n{errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2daae-c306-4e59-a3ba-970b1da06dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f962980-d865-482e-a4aa-10068342bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A string with a syntactic error (\"zulu\") and a semantic error (\"th after 99\")\n",
    "test_text_multiple_errors = \"Monday, zulu, th after 99, th after 5, wed\"\n",
    "\n",
    "print(f\"Checking: '{test_text_multiple_errors}'\")\n",
    "ok, constraints, errors = validate_and_parse_all_constraints(\n",
    "    constraint_parser, test_text_multiple_errors\n",
    ")\n",
    "\n",
    "if ok:\n",
    "    print(\"\\nSuccess! Parsed constraints:\")\n",
    "    # Assuming your constraints have a __str__ or __repr__ method\n",
    "    for c in constraints:\n",
    "        print(f\"  - {c}\")\n",
    "else:\n",
    "    print(f\"\\nFailure! Reasons:\\n{errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1fe5d15-9fb2-4f3c-882f-3147800e61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grammar validates ranges and solves ambiguity!\n",
    "GRAMMAR_V3 = r\"\"\"\n",
    "    ?start: tod\n",
    "    \n",
    "    tod: std_time | military_time\n",
    "\n",
    "    // RULES\n",
    "    std_time: STD_HOUR (\":\" MINUTE)? AM_PM?\n",
    "    military_time: MILITARY_TIME\n",
    "\n",
    "    // TERMINALS -- These now perform the validation!\n",
    "    \n",
    "    // Matches a full, valid 24-hour time string like \"2359\" or \"0830\"\n",
    "    MILITARY_TIME: /([01]\\d|2[0-3])[0-5]\\d/ \n",
    "    \n",
    "    // Matches a valid 12-hour format hour, like \"12\" or \"9\"\n",
    "    STD_HOUR: /1[0-2]|[1-9]/\n",
    "\n",
    "    // Matches a valid minute, like \"05\" or \"59\"\n",
    "    MINUTE: /[0-5]\\d/\n",
    "\n",
    "    AM_PM: \"am\"i | \"pm\"i\n",
    "    \n",
    "    %ignore /\\s+/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cbdedd6-793f-4cf9-8ce3-1ed77394c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "\n",
    "from lark import Lark, Transformer, v_args\n",
    "\n",
    "\n",
    "@v_args(inline=True)\n",
    "class ConstraintTransformerV2(Transformer):\n",
    "    \"\"\"Transforms the parsed Lark tree into constraint objects.\"\"\"\n",
    "\n",
    "    def STD_HOUR(self, h):\n",
    "        return int(h)\n",
    "\n",
    "    def MINUTE(self, m):\n",
    "        return int(m)\n",
    "\n",
    "    def AM_PM(self, am_pm):\n",
    "        return am_pm.lower()\n",
    "\n",
    "    # This method receives the validated 4-digit string from MILITARY_TIME\n",
    "    def military_time(self, token):\n",
    "        hour = int(token[0:2])\n",
    "        minute = int(token[2:4])\n",
    "        return (hour, minute)\n",
    "\n",
    "    @v_args(inline=False)\n",
    "    def tod(self, children):\n",
    "        if not children:\n",
    "            return None\n",
    "        h, m = children[0]\n",
    "        return time(h, m)\n",
    "\n",
    "    # This logic is mostly the same as before, just cleaner.\n",
    "    @v_args(inline=False)\n",
    "    def std_time(self, children):\n",
    "        h = children[0]\n",
    "        m = 0\n",
    "        fmt = None\n",
    "\n",
    "        # Unpack the optional minute and am/pm\n",
    "        if len(children) > 1:\n",
    "            if isinstance(children[1], str):  # It's AM/PM\n",
    "                fmt = children[1]\n",
    "            else:  # It's a minute\n",
    "                m = children[1]\n",
    "\n",
    "        if len(children) > 2:  # Must be AM/PM if minute was also present\n",
    "            fmt = children[2]\n",
    "\n",
    "        # Apply AM/PM logic\n",
    "        if fmt == \"pm\" and h != 12:\n",
    "            h += 12\n",
    "        elif fmt == \"am\" and h == 12:  # Handle midnight case: 12am is 00:00\n",
    "            h = 0\n",
    "        elif fmt is None:  # No am/pm specified\n",
    "            # Your original logic for inferring am/pm\n",
    "            if h in [1, 2, 3, 4, 5, 6, 7, 12]:\n",
    "                h += 12\n",
    "            if h == 24:  # 12pm becomes 24, should be 12\n",
    "                h = 12\n",
    "        return (h, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ca26c4a-ab1d-4cc9-a52d-cd0e320a3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly failed to parse '2500'!\n",
      "Unexpected token Token('STD_HOUR', '5') at line 1, column 2.\n",
      "Expected one of: \n",
      "\t* $END\n",
      "\t* AM_PM\n",
      "\t* COLON\n",
      "Previous tokens: [Token('STD_HOUR', '2')]\n",
      "\n",
      "\n",
      "Correctly failed to parse '1061'!\n",
      "Unexpected token Token('STD_HOUR', '6') at line 1, column 3.\n",
      "Expected one of: \n",
      "\t* $END\n",
      "\t* AM_PM\n",
      "\t* COLON\n",
      "Previous tokens: [Token('STD_HOUR', '10')]\n",
      "\n",
      "\n",
      "--- Parsing '1000' ---\n",
      "res = 10:00:00\n",
      "\n",
      "--- Parsing '10am' ---\n",
      "res = 10:00:00\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, UnexpectedToken\n",
    "\n",
    "# ... (define the transformer and other helpers here) ...\n",
    "\n",
    "\n",
    "def constraint_parser(grammar=GRAMMAR_V3, debug=False):\n",
    "    # Use the new Transformer\n",
    "    constraint_transformer = ConstraintTransformerV2()\n",
    "    global DEBUG\n",
    "    DEBUG = debug\n",
    "    return Lark(grammar, parser=\"lalr\", transformer=constraint_transformer, debug=debug)\n",
    "\n",
    "\n",
    "parser = constraint_parser()\n",
    "\n",
    "# --- This will now fail, as desired! ---\n",
    "try:\n",
    "    parser.parse(\"2500\")\n",
    "except UnexpectedToken as e:\n",
    "    print(\"Correctly failed to parse '2500'!\")\n",
    "    print(e)\n",
    "\n",
    "# --- This will also fail ---\n",
    "try:\n",
    "    parser.parse(\"1061\")\n",
    "except UnexpectedToken as e:\n",
    "    print(\"\\nCorrectly failed to parse '1061'!\")\n",
    "    print(e)\n",
    "\n",
    "# --- These will succeed ---\n",
    "print(\"\\n--- Parsing '1000' ---\")\n",
    "result = parser.parse(\"1000\")\n",
    "print(f\"res = {result}\")\n",
    "\n",
    "print(\"\\n--- Parsing '10am' ---\")\n",
    "result = parser.parse(\"10am\")\n",
    "print(f\"res = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56eb41-33e0-4d10-9a92-2ff095aa7576",
   "metadata": {},
   "source": [
    "# Notes on EBNF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2da6c7-453a-4511-88a6-a2d8d478f2cc",
   "metadata": {},
   "source": [
    "## The Jupyternaut Prescription for Lark Transformers\n",
    "\n",
    "Here is a concise guide with minimal examples to serve as your mental model. Think of this as the \"Standard Model\" for connecting your grammar to your transformer.\n",
    "\n",
    "The fundamental principle is: **For every possible path a rule can take, there must be a corresponding method in the transformer to handle it.**\n",
    "\n",
    "### Case 1: The Default Rule (No Alias)\n",
    "\n",
    "This is the simplest case. The method name in your transformer **must exactly match** the rule name in your grammar.\n",
    "\n",
    "*   **Grammar Snippet (EBNF):**\n",
    "    ```lark\n",
    "    time_range: time \"-\" time\n",
    "    ```\n",
    "*   **How to Identify:** A simple rule name (`time_range`) defined with a colon (`:`).\n",
    "*   **Transformer Snippet (Python):**\n",
    "    ```python\n",
    "    class MyTransformer(Transformer):\n",
    "        # Method name matches the rule name\n",
    "        def time_range(self, children):\n",
    "            # children will be a list of the processed parts, e.g., [900, 1700]\n",
    "            start_time, end_time = children\n",
    "            return (start_time, end_time)\n",
    "    ```\n",
    "\n",
    "### Case 2: The Alias Rule (The `->` Arrow)\n",
    "\n",
    "The alias (`->`) completely overrides the default behavior. Lark will ignore the rule name and look for a method matching the alias name.\n",
    "\n",
    "*   **Grammar Snippet (EBNF):**\n",
    "    ```lark\n",
    "    time_range: time \"-\" time -> build_explicit_range\n",
    "    ```\n",
    "*   **How to Identify:** Look for the arrow `->` followed by a new name (`build_explicit_range`).\n",
    "*   **Transformer Snippet (Python):**\n",
    "    ```python\n",
    "    class MyTransformer(Transformer):\n",
    "        # Method name matches the ALIAS name\n",
    "        def build_explicit_range(self, children):\n",
    "            start_time, end_time = children\n",
    "            return (start_time, end_time)\n",
    "    ```\n",
    "\n",
    "### Case 3: The \"Or\" Rule (Multiple Branches)\n",
    "\n",
    "This is the one that caught you, and it's just a combination of the first two cases. You must treat each branch (separated by a `|`) as its own independent path.\n",
    "\n",
    "*   **Grammar Snippet (EBNF):**\n",
    "    ```lark\n",
    "    range: time \"-\" time -> build_explicit_range  // Path 1 (Alias)\n",
    "         | \"until\"i time                        // Path 2 (Default)\n",
    "    ```\n",
    "*   **How to Identify:** Look for the vertical bar `|` separating different patterns. Check each pattern for an alias.\n",
    "*   **Transformer Snippet (Python):** You need one method for each path.\n",
    "    ```python\n",
    "    class MyTransformer(Transformer):\n",
    "        # Method for Path 1, matching the alias\n",
    "        def build_explicit_range(self, children):\n",
    "            start_time, end_time = children\n",
    "            return (start_time, end_time)\n",
    "\n",
    "        # Method for Path 2, matching the RULE name (\"range\")\n",
    "        def range(self, children):\n",
    "            # This branch only has one child: the processed `time`\n",
    "            end_time = children[0]\n",
    "            return (0, end_time) # from start of day until the time\n",
    "    ```\n",
    "\n",
    "### Case 4: Transforming Terminals (The Uppercase Tokens)\n",
    "\n",
    "You can also write methods for the \"atoms\" of your grammar—the Terminals (usually in `ALL_CAPS`). This is extremely useful for converting raw text into useful data types like numbers or dates.\n",
    "\n",
    "*   **Grammar Snippet (EBNF):**\n",
    "    ```lark\n",
    "    INT: /[0-9]+/\n",
    "    ```\n",
    "*   **How to Identify:** A token name in all caps.\n",
    "*   **Transformer Snippet (Python):**\n",
    "    ```python\n",
    "    class MyTransformer(Transformer):\n",
    "        # Method name matches the Terminal name\n",
    "        def INT(self, number_token):\n",
    "            # The argument is the token object itself\n",
    "            # We convert its string value to a Python integer\n",
    "            return int(number_token.value)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb30ff4-714f-421b-be56-c65f24e3d002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rehearsal Scheduler",
   "language": "python",
   "name": "rehearsal-scheduler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
